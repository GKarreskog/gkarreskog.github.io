---
layout: default
---

<!-- # Welcom to my web page -->
# Gustav Karreskog 
<!-- ## About Me  -->
* * * 

I am a Ph.D. student in economics at the Stocholm School of Economics on the academic job market 2020/2021. 

My reasearch is primarily in the intersection of microeconomic theory and experimental economics. In particular, my research aims at understanding boundedly rational decision making, how incentives and experience guide human decision making via learning and heuristics, and how it impacts population behavior and economic outcomes. 

[Download my CV](CV - Gustav Karreskog.pdf)

## Job Market Paper 
* * *

<h3 class="paper-title">Rational Heuristics Predicts Behavior in One-Shot Games </h3>
_with [Frederick Callaway](https://fredcallaway.com/) and [Thomas L. Griffiths](https://psych.princeton.edu/person/tom-griffiths) (draft available on request)_

**Abstract:** 
We present a theory of human behavior in one-shot games as being the result of rational use of heuristics. To test this theory, we first define a broad family of possible heuristics and an associated family of cognitive cost functions. We then ask whether human behavior in a newly collected large dataset of one-shot normal form games is well-explained by the optimal use of heuristics. In particular, we design the experiment to test a key prediction of the theory: the heuristics people employ will be adapted to the environment in which they are used. We find that the behavior of the experimental subjects is consistent with and well explained by heuristic reasoning and optimal use of limited cognitive resources. Furthermore, we show that this rational use of heuristics can have a substantial and predictable impact on the behavior in any single game.

## Working Papers 
* * * 

<h3 class="paper-title">Learning about Initial Play Determines Average Cooperation in Repeated Games</h3>
_with [Drew Fudenberg](http://economics.mit.edu/faculty/drewf) (draft available on request)_ 

**Abstract:** 
We propose a simple learning model to make out of sample predictions of cooperation rates across treatments in the experimental play of the indefinitely repeated prisoner's dilemma. Although the model has only 4 parameters, it performs almost as well as more complicated models and machine learning algorithms. We find that learning has the most effect on choices in the initial round of each supergame, and that whether cooperation rises or falls in the course of a session depends on the way the initial choices in a supergame determine play in subsequent rounds. Our results also explain past findings on the impact of the risk dominance considerations. 

<div class="distance"></div>


<h3 class="paper-title"><a href="https://arxiv.org/abs/2009.12910">Stochastic Stability of a Recency Weighted Sampling Dynamic</a></h3>
_with [Alexander Aurell](http://economics.mit.edu/faculty/drewf) ([arXiv](https://arxiv.org/abs/2009.12910), [PDF](2009.12910.pdf))_

**Abstract:**
It is common to model learning in games so that either a deterministic process or a finite state Markov chain describes the evolution of play. Such processes can however produce undesired outputs, where the players' behavior is heavily influenced by the modeling. In simulations we see how the assumptions in (Young, 1993), a well-studied model for stochastic stability, lead to unexpected behavior in games without strict equilibria, such as Matching Pennies. The behavior should be considered a modeling artifact. In this paper we propose a continuous-state space model for learning in games that can converge to mixed Nash equilibria, the Recency Weighted Sampler (RWS). The RWS is similar in spirit Young's model, but introduces a notion of best response where the players sample from a recency weighted history of interactions. We derive properties of the RWS which are known to hold for finite-state space models of adaptive play, such as the convergence to and existence of a unique invariant distribution of the process, and the concentration of that distribution on minimal CURB blocks. Then, we establish conditions under which the RWS process concentrates on mixed Nash equilibria inside minimal CURB blocks. While deriving the results, we develop a methodology that is relevant for a larger class of continuous state space learning models. 

## Publication in Mathematics
* * * 
<h3 class="paper-title"><a href="https://www.ams.org/proc/2016-144-03/S0002-9939-2015-12784-0/">Schr√∂dinger operators on graphs: symmetrization and Eulerian cycles</a></h3>
_with [Isak Trygg Kupersmidt](https://www.hhs.se/en/research/departments/de/people/kupersmidt-isak/) and [Pavel Kurasov](https://staff.math.su.se/kurasov/)_<br>
_Proceedings of the American Mathematical Society_ 144.3 (2016): 1197-1207. ([Journal](https://www.ams.org/proc/2016-144-03/S0002-9939-2015-12784-0), [PDF](2015-Report3.pdf))

**Abstract:** 
Spectral properties of the Schrodinger operator on a finite compact metric graph with delta-type vertex conditions are discussed. Explicit estimates for the lowest eigenvalue (ground state) are obtained using two different methods: Eulerian cycle and symmetrization techniques.


## Work in Progress 
* * *
<h3 class="paper-title"> Cue based decision making and context effects</h3>
_with [Benjamin Mandl](https://www.hhs.se/sv/persons/m/mandl-benjamin/)_ 

**Description**
We seek to understand context effets, such as default- and decoy-effects, from the perspective of adaptive heuristics. The fundamental insight is that when a decision maker face a decision problem where she is uncertain about the values of different alternatives, the context and cues can affect the conditional expectation of the different values, even if they do not directly influence the value of the options. If a default is set because someone with good intentions and better information recommends it, conditioning on that information should affect the decision of an uncertain but rational DM. If the default is set randomly on the other hand, even uncertain DM should ignore it. We seek to test if this can explain known decoy effects by comparing situations where the conditional expectation should and shoud not change based on the cues, in otherwise identical situations. 
