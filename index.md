---
layout: default
---

<!-- # Welcom to my web page -->
# Gustav Karreskog Rehbinder
<!-- ## About Me  -->
* * *

I am currently a Postdoc at the Department of Economics at Uppsala University. I completed my Ph.D. at Stockholm School of Economics in the Spring of 2021.

My reasearch is primarily in the intersection of microeconomic theory and experimental economics. In particular, my research aims at understanding boundedly rational decision making, how incentives and experience guide human decision making via learning and heuristics, and how it impacts population behavior and economic outcomes.

[Download my CV](files/CV - Gustav Karreskog.pdf)

## Publications 
* * *
<h3 class="paper-title"><a href="files/Fudenberg & Karreskog - 2022.pdf">Predicting Cooperation with Learning Models</a></h3>
_[American Economic Journal: Microeconomics, 2024, 16 (1): 1-32](https://www.aeaweb.org/articles?id=10.1257/mic.20220148)_<br>
_with [Drew Fudenberg](http://economics.mit.edu/faculty/drewf) ([PDF](files/Fudenberg & Karreskog - 2022.pdf), [Online Appendix](files/Online appendix - Fudenberg & Karreskog - 2022.pdf))_ 

**Abstract:**
We use simulations of a simple learning model to predict cooperation rates in the experimental play of the indefinitely repeated prisoner's dilemma.  We suppose that learning and the game parameters only influence play in the initial round of each supergame, and that after these rounds play depends only on the outcome of the previous round.  We find that our model predicts out-of-sample cooperation at least as well as models with more parameters  and harder-to-interpret  machine learning algorithms.  Our results let us predict the effect of  session length and help explain  past findings on the role of strategic uncertainty. 


## Working Papers
* * *
<h3 class="paper-title"><a href="files/Callaway, Griffiths & Karreskog Rehbinder - 2024.pdf">Rational Heuristics for One-Shot Games </a></h3>
_with [Frederick Callaway](https://fredcallaway.com/) and [Thomas L. Griffiths](https://psych.princeton.edu/person/tom-griffiths) ([PDF](files/Callaway, Griffiths & Karreskog Rehbinder - 2024.pdf))_ Latest version: March 2024

**Abstract:**
We present a theory of human behavior in one-shot interactions based on the assumption that people use heuristics that optimally trade off expected payoff and cognitive costs. The theory predicts that people's behavior will depend on their past experience; specifically, they will make choices using heuristics that would have performed well in previously played games. We confirm this prediction in a large, preregistered experiment. The rational heuristics model provides a strong quantitative account of participant behavior, outperforming existing models. More broadly, our results suggest that synthesizing heuristic and optimal models is a powerful tool for understanding and predicting economic decisions.
<div class="distance"></div>

<h3 class="paper-title"><a href="files/Forsgren, Karreskog Rehbinder & Mandl - 2024.pdf">You can fool some of the people some of the time but you can help everyone forever: learning and effective nudging</a></h3>
_with [Mattias Forsgren](https://www.katalog.uu.se/empinfo/?id=N21-767) and [Benjamin Mandl](https://www.hhs.se/sv/persons/m/mandl-benjamin/) ([PDF] (files/Forsgren, Karreskog Rehbinder & Mandl - 2024.pdf))_ Latest version: July 2024

**Abstract**
Why do nudges sometimes fail to deliver the promised behaviour change? We argue that part of the explanation may be that people learn whether the nudge is guiding them towards their goals or not. In an experiment, we show that participants quickly learn to choose in accordance with a nudge proportionally to how well it predicts the superior option. This illustrates a more general point: unless choice architects align their nudging with the goals of the nudgee, the latter's capacity to learn and make inferences may allow them to come up with strategies to avoid being nudged.


<h3 class="paper-title"><a href="https://arxiv.org/abs/2009.12910">Stochastic Stability of a Recency Weighted Sampling Dynamic</a></h3>
_with [Alexander Aurell](http://www.aurell.st) ([arXiv](https://arxiv.org/abs/2009.12910), [PDF](files/2009.12910.pdf))_ Latest version: September 2020

**Abstract:**
It is common to model learning in games so that either a deterministic process or a finite state Markov chain describes the evolution of play. Such processes can however produce undesired outputs, where the players' behavior is heavily influenced by the modeling. In simulations we see how the assumptions in (Young, 1993), a well-studied model for stochastic stability, lead to unexpected behavior in games without strict equilibria, such as Matching Pennies. The behavior should be considered a modeling artifact. In this paper we propose a continuous-state space model for learning in games that can converge to mixed Nash equilibria, the Recency Weighted Sampler (RWS). The RWS is similar in spirit Young's model, but introduces a notion of best response where the players sample from a recency weighted history of interactions. We derive properties of the RWS which are known to hold for finite-state space models of adaptive play, such as the convergence to and existence of a unique invariant distribution of the process, and the concentration of that distribution on minimal CURB blocks. Then, we establish conditions under which the RWS process concentrates on mixed Nash equilibria inside minimal CURB blocks. While deriving the results, we develop a methodology that is relevant for a larger class of continuous state space learning models.

## Publication in Mathematics
* * *
<h3 class="paper-title"><a href="https://www.ams.org/proc/2016-144-03/S0002-9939-2015-12784-0/">Schrödinger operators on graphs: symmetrization and Eulerian cycles</a></h3>
_with [Isak Trygg Kupersmidt](https://www.hhs.se/en/research/departments/de/people/kupersmidt-isak/) and [Pavel Kurasov](https://staff.math.su.se/kurasov/)_<br>
_Proceedings of the American Mathematical Society_ 144.3 (2016): 1197-1207. ([Journal](https://www.ams.org/proc/2016-144-03/S0002-9939-2015-12784-0), [PDF](files/2015-Report3.pdf))

**Abstract:**
Spectral properties of the Schrodinger operator on a finite compact metric graph with delta-type vertex conditions are discussed. Explicit estimates for the lowest eigenvalue (ground state) are obtained using two different methods: Eulerian cycle and symmetrization techniques.


## Work in Progress
* * *
<h3 class="paper-title">Naturally formed preferences are transitive</h3>
_with [Mattias Forsgren](https://www.katalog.uu.se/empinfo/?id=N21-767) and [Peter Juslin](https://www.uu.se/en/contact-and-organisation/staff?query=XX3971)_

**Description**
Transitive preferences is a central feature of a competent, coherence rational decision maker and a common assumption in formal theories. Almost all previous psychological investigations of transitivity of preferences have used artificial options exhaustively defined by a list of properties (typically so-called monetary gambles). Yet, cognitive theories of judgement and decision making fundamentally seek to make claims about preferences for objects we encounter in the real world. Here, we sample such objects and investigate the “Fechnerian” theory that (covert) preferences are fundamentally transitive but that (overt) choices are made with noise and thus may violate transitivity depending on how clearly one object is preferred over the other. When one object is strongly preferred, the overt choices will align with the covert transitive preferences. When differences in strength of preference are smaller, overt choices are more likely to violate the covert preferences. Strength of preference is, in turn, mediated by “learning what you like” from familiarity with the object. We perform two large sample experiments to test this theory. Regression analyses on judgements are (i) consistent with the chain just described. Model comparison on choices (ii) favours the kind of model described above and (iii) indicates little to no existence of intransitive preferences for objects. Transitive preferences appears to be a safe assumption for formal theories in so far as their scope is choices between familiar objects.


<h3 class="paper-title"> Estimation of Learning Models Using Approximate Bayesian Computation</h3>
An important question is how to best estimate learning models based on experimental data. Common approaches involving estimating individual parameters based on the exact sequence of decisions made are known to have problems such as low power and biased estimates, (Salmon, 2001; Wilcox 2006). In this project, I suggest that instead of focusing on each decision taken by the individuals, we should search for learning models that are likely to reproduce the time-path of the population's behavior. By considering data simulated under different assumptions, I show that using Approximate Bayesian Computation to find the learning models that are most likely to reproduce the population's time-path, we get more reliable estimates of the learning models. Furthermore, this way, we make sure we capture the learning models' aspects with the most important implications. Lastly, I apply this method on existing data to derive new conclusions.
